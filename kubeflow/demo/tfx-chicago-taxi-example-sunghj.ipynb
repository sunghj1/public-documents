{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFX Chicago Taxi Example 수행과정\n",
    "\n",
    "참조 원본 : https://www.kangwoo.kr/2020/09/13/tfx-%ec%8b%9c%ec%b9%b4%ea%b3%a0-%ed%83%9d%ec%8b%9c/\n",
    "\n",
    "### 1. 본 코드(.ipynb)를 수행하기 위한 전제조건 \n",
    "* Kubeflow 환경\n",
    "* Nobtebook server를 생성할 때, 다음의 조건을 만족할 것.\n",
    "    * tensorflow 2.0 이후 버전으로 notebook server 구동\n",
    "        * image : gcr.io/kubeflow-images-public/tensorflow-2.1.0-notebook-cpu:1.0.0\n",
    "    * nbserver 생성시 데이터 관리를 위한 pv를 추가로 생성 (ReadWriteMany) \n",
    "        * name : nbserver-tfx-chicago-taxi-example-vol-1\n",
    "        * /home/jovyan/data-vol-1 에 마운트.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 필요한 패키지 설치 \n",
    "반드시 다음의 순서를 엄수해야 한다.\n",
    "왜냐하면, kubeflow가 제공하는 tenworflow jupyter notebook container에서 pip로 설치 시.. \n",
    "* 기본으로 설치되어 있는 pip 버전은 19.x 이다.\n",
    "* tfx는 pip 20 이상에서 무한 로딩이 지속되는 문제가 있다.\n",
    "* kfp는 pip 20 아래에서는 오류가 나며 설치가 되지 않는다.\n",
    "\n",
    "그래서, 먼저 pip 19 환경에서 tfx를 설치하고, pip를 최신으로 업그레이드 한 후 kfp를 설치해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tfx==0.22.0 --user --no-cache-dir\n",
    "# !pip install pip --upgrade --user --no-cache-dir\n",
    "# !pip install kfp --user --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 환경변수 설정\n",
    "pip install시에 나오는 메시지에 반응하기 위해.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PATH=${PATH}:/home/jovyan/.local/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재시도 지원을 위해, 기존 데이터를 삭제."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/home/jovyan/data-vol-1/tfx/__pycache__/taxi_utils.cpython-36.pyc': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00000-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00001-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00002-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00003-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00004-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00005-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00006-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00007-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00008-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00009-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00010-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00011-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00012-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00013-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00014-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/train/data_tfrecord-00015-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00000-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00001-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00002-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00003-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00004-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00005-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00006-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00007-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00008-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00009-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00010-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00011-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00012-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00013-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00014-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/59/eval/data_tfrecord-00015-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00000-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00001-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00002-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00006-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00003-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00004-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00005-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00007-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00008-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00009-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00010-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00011-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00012-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00013-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00014-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/train/data_tfrecord-00015-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00000-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00001-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00002-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00003-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00004-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00005-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00006-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00007-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00008-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00009-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00010-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00011-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00012-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00013-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00014-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/CsvExampleGen/examples/69/eval/data_tfrecord-00015-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/StatisticsGen/statistics/60/train/stats_tfrecord': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/StatisticsGen/statistics/60/eval/stats_tfrecord': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/StatisticsGen/statistics/70/train/stats_tfrecord': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/StatisticsGen/statistics/70/eval/stats_tfrecord': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/SchemaGen/schema/61/schema.pbtxt': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/SchemaGen/schema/71/schema.pbtxt': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/ExampleValidator/anomalies/62/anomalies.pbtxt': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/ExampleValidator/anomalies/73/anomalies.pbtxt': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/63/metadata/schema.pbtxt': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/63/transformed_metadata/schema.pbtxt': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/63/transform_fn/assets/vocab_compute_and_apply_vocabulary_vocabulary': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/63/transform_fn/assets/vocab_compute_and_apply_vocabulary_1_vocabulary': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/63/transform_fn/variables': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/72/metadata/schema.pbtxt': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/72/transformed_metadata/schema.pbtxt': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/72/transform_fn/assets/vocab_compute_and_apply_vocabulary_vocabulary': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/72/transform_fn/assets/vocab_compute_and_apply_vocabulary_1_vocabulary': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transform_graph/72/transform_fn/variables': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00000-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00001-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00002-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00003-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00004-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00005-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00006-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00007-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00008-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00009-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00010-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00011-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00012-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00013-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00014-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/train/transformed_examples-00015-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00000-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00001-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00002-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00003-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00004-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00005-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00006-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00007-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00008-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00009-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00010-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00011-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00012-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00013-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00014-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/63/eval/transformed_examples-00015-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00000-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00001-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00002-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00003-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00004-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00005-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00006-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00007-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00008-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00009-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00010-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00011-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00012-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00013-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00014-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/train/transformed_examples-00015-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00000-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00001-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00002-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00003-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00004-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00005-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00006-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00007-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00008-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00009-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00010-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00011-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00012-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00013-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00014-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Transform/transformed_examples/72/eval/transformed_examples-00015-of-00016.gz': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/64/serving_model_dir/variables/variables.data-00000-of-00001': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/64/serving_model_dir/variables/variables.index': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/64/serving_model_dir/assets/vocab_compute_and_apply_vocabulary_vocabulary': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/64/serving_model_dir/assets/vocab_compute_and_apply_vocabulary_1_vocabulary': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/64/serving_model_dir/saved_model.pb': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/74/serving_model_dir/variables/variables.data-00000-of-00001': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/74/serving_model_dir/variables/variables.index': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/74/serving_model_dir/assets/vocab_compute_and_apply_vocabulary_vocabulary': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/74/serving_model_dir/assets/vocab_compute_and_apply_vocabulary_1_vocabulary': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Trainer/model/74/serving_model_dir/saved_model.pb': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/blessing/65/BLESSED': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/blessing/75/BLESSED': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/evaluation/65/metrics': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/evaluation/65/validations': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/evaluation/65/eval_config.json': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/evaluation/65/plots': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/evaluation/75/metrics': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/evaluation/75/validations': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/evaluation/75/eval_config.json': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Evaluator/evaluation/75/plots': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/InfraValidator/blessing/66/INFRA_NOT_BLESSED': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/InfraValidator/blessing/76/INFRA_NOT_BLESSED': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/.temp': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Pusher/pushed_model/67': Permission denied\n",
      "rm: cannot remove '/home/jovyan/data-vol-1/pipelines/tfx/kubeflow_chicago_taxi_pipeline_demo/Pusher/pushed_model/77': Permission denied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './taxi_utils.py': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /home/jovyan/data-vol-1/tfx\n",
    "!rm -rf /home/jovyan/data-vol-1/pipelines\n",
    "!rm ./taxi_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이쯤에서, kernel restart를 해 주자.\n",
    "\n",
    "\n",
    "### 4. train을 위한 원본 데이터를 받아오기.\n",
    "\n",
    "notebook server 생성시 만든 pv는 당연히 notebook server에서도 마운트되어 있지만, 나중에 TFX 실행 pod에서도 마운트해서 활용하게 된다.  \n",
    "TFX pod에서 작업에 필요한 원본 데이터를 받아갈 수 있도록, notebook server에 마운트 된 위치에 파일을 받아 저장해 놓는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-01 02:47:23--  https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1922812 (1.8M) [text/plain]\n",
      "Saving to: ‘/home/jovyan/data-vol-1/tfx/data/data.csv’\n",
      "\n",
      "data.csv            100%[===================>]   1.83M  6.46MB/s    in 0.3s    \n",
      "\n",
      "2021-04-01 02:47:24 (6.46 MB/s) - ‘/home/jovyan/data-vol-1/tfx/data/data.csv’ saved [1922812/1922812]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /home/jovyan/data-vol-1/tfx/data/ \n",
    "!wget -P /home/jovyan/data-vol-1/tfx/data/ https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 가정 : 데이터 분석가는 데이터 분석에 필요한 코드 작성 및 테스트를 이미 수행했다고 가정한다.\n",
    "> 그리고, 그 결과로 도출된 tfx python code의 내용이 이미 준비되어 있다고 가정한다.\n",
    "> 바로 그 code 가 다음의 taxi_utils.py 이다.\n",
    "\n",
    "### 5. taxi_utils.py 코드 생성 \n",
    "\n",
    "taxi_utils.py 파일이 ipynb 파일의 위치와 같은 곳에 생성된다. (/home/jovyan/taxi_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_taxi_utils_filename = 'taxi_utils.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing taxi_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_taxi_utils_filename}\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from typing import List, Text\n",
    "\n",
    "import absl\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "from tfx.components.trainer.executor import TrainerFnArgs\n",
    "\n",
    "# Categorical features are assumed to each have a maximum value in the dataset.\n",
    "_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n",
    "\n",
    "_CATEGORICAL_FEATURE_KEYS = [\n",
    "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
    "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
    "    'dropoff_community_area'\n",
    "]\n",
    "\n",
    "_DENSE_FLOAT_FEATURE_KEYS = ['trip_miles', 'fare', 'trip_seconds']\n",
    "\n",
    "# Number of buckets used by tf.transform for encoding each feature.\n",
    "_FEATURE_BUCKET_COUNT = 10\n",
    "\n",
    "_BUCKET_FEATURE_KEYS = [\n",
    "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "    'dropoff_longitude'\n",
    "]\n",
    "\n",
    "# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n",
    "_VOCAB_SIZE = 1000\n",
    "\n",
    "# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n",
    "_OOV_SIZE = 10\n",
    "\n",
    "_VOCAB_FEATURE_KEYS = [\n",
    "    'payment_type',\n",
    "    'company',\n",
    "]\n",
    "\n",
    "# Keys\n",
    "_LABEL_KEY = 'tips'\n",
    "_FARE_KEY = 'fare'\n",
    "\n",
    "def _transformed_name(key):\n",
    "  return key + '_xf'\n",
    "\n",
    "def _transformed_names(keys):\n",
    "  return [_transformed_name(key) for key in keys]\n",
    "\n",
    "def _gzip_reader_fn(filenames):\n",
    "  \"\"\"Small utility returning a record reader that can read gzip'ed files.\"\"\"\n",
    "  return tf.data.TFRecordDataset(\n",
    "      filenames,\n",
    "      compression_type='GZIP')\n",
    "\n",
    "def _fill_in_missing(x):\n",
    "  \"\"\"Replace missing values in a SparseTensor.\n",
    "\n",
    "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
    "\n",
    "  Args:\n",
    "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
    "      in the second dimension.\n",
    "\n",
    "  Returns:\n",
    "    A rank 1 tensor where missing values of `x` have been filled in.\n",
    "  \"\"\"\n",
    "  default_value = '' if x.dtype == tf.string else 0\n",
    "  return tf.squeeze(\n",
    "      tf.sparse.to_dense(\n",
    "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
    "          default_value),\n",
    "      axis=1)\n",
    "\n",
    "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "  \"\"\"Returns a function that parses a serialized tf.Example and applies TFT.\"\"\"\n",
    "\n",
    "  model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "  @tf.function\n",
    "  def serve_tf_examples_fn(serialized_tf_examples):\n",
    "    \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "    feature_spec = tf_transform_output.raw_feature_spec()\n",
    "    feature_spec.pop(_LABEL_KEY)\n",
    "    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
    "\n",
    "    transformed_features = model.tft_layer(parsed_features)\n",
    "    # TODO(b/148082271): Remove this line once TFT 0.22 is used.\n",
    "    transformed_features.pop(_transformed_name(_LABEL_KEY), None)\n",
    "\n",
    "    return model(transformed_features)\n",
    "\n",
    "  return serve_tf_examples_fn\n",
    "\n",
    "def _input_fn(file_pattern: Text,\n",
    "              tf_transform_output: tft.TFTransformOutput,\n",
    "              batch_size: int = 200) -> tf.data.Dataset:\n",
    "  \"\"\"Generates features and label for tuning/training.\n",
    "\n",
    "  Args:\n",
    "    file_pattern: input tfrecord file pattern.\n",
    "    tf_transform_output: A TFTransformOutput.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  transformed_feature_spec = (\n",
    "      tf_transform_output.transformed_feature_spec().copy())\n",
    "\n",
    "  dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "      file_pattern=file_pattern,\n",
    "      batch_size=batch_size,\n",
    "      features=transformed_feature_spec,\n",
    "      reader=_gzip_reader_fn,\n",
    "      label_key=_transformed_name(_LABEL_KEY))\n",
    "\n",
    "  return dataset\n",
    "\n",
    "def _build_keras_model(hidden_units: List[int] = None) -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying taxi data.\n",
    "\n",
    "  Args:\n",
    "    hidden_units: [int], the layer sizes of the DNN (input layer first).\n",
    "\n",
    "  Returns:\n",
    "    A keras Model.\n",
    "  \"\"\"\n",
    "  real_valued_columns = [\n",
    "      tf.feature_column.numeric_column(key, shape=())\n",
    "      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n",
    "  ]\n",
    "  categorical_columns = [\n",
    "      tf.feature_column.categorical_column_with_identity(\n",
    "          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n",
    "      for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n",
    "  ]\n",
    "  categorical_columns += [\n",
    "      tf.feature_column.categorical_column_with_identity(\n",
    "          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n",
    "      for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n",
    "  ]\n",
    "  categorical_columns += [\n",
    "      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n",
    "          key,\n",
    "          num_buckets=num_buckets,\n",
    "          default_value=0) for key, num_buckets in zip(\n",
    "              _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n",
    "              _MAX_CATEGORICAL_FEATURE_VALUES)\n",
    "  ]\n",
    "  indicator_column = [\n",
    "      tf.feature_column.indicator_column(categorical_column)\n",
    "      for categorical_column in categorical_columns\n",
    "  ]\n",
    "\n",
    "  model = _wide_and_deep_classifier(\n",
    "      wide_columns=indicator_column,\n",
    "      deep_columns=real_valued_columns,\n",
    "      dnn_hidden_units=hidden_units or [100, 70, 50, 25])\n",
    "  return model\n",
    "\n",
    "def _wide_and_deep_classifier(wide_columns, deep_columns, dnn_hidden_units):\n",
    "  \"\"\"Build a simple keras wide and deep model.\n",
    "\n",
    "  Args:\n",
    "    wide_columns: Feature columns wrapped in indicator_column for wide (linear)\n",
    "      part of the model.\n",
    "    deep_columns: Feature columns for deep part of the model.\n",
    "    dnn_hidden_units: [int], the layer sizes of the hidden DNN.\n",
    "\n",
    "  Returns:\n",
    "    A Wide and Deep Keras model\n",
    "  \"\"\"\n",
    "  # Following values are hard coded for simplicity in this example,\n",
    "  # However prefarably they should be passsed in as hparams.\n",
    "\n",
    "  # Keras needs the feature definitions at compile time.\n",
    "  input_layers = {\n",
    "      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)\n",
    "      for colname in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n",
    "  }\n",
    "  input_layers.update({\n",
    "      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n",
    "      for colname in _transformed_names(_VOCAB_FEATURE_KEYS)\n",
    "  })\n",
    "  input_layers.update({\n",
    "      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n",
    "      for colname in _transformed_names(_BUCKET_FEATURE_KEYS)\n",
    "  })\n",
    "  input_layers.update({\n",
    "      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n",
    "      for colname in _transformed_names(_CATEGORICAL_FEATURE_KEYS)\n",
    "  })\n",
    "\n",
    "  # TODO(b/144500510): SparseFeatures for feature columns + Keras.\n",
    "  deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)\n",
    "  for numnodes in dnn_hidden_units:\n",
    "    deep = tf.keras.layers.Dense(numnodes)(deep)\n",
    "  wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)\n",
    "\n",
    "  output = tf.keras.layers.Dense(\n",
    "      1, activation='sigmoid')(\n",
    "          tf.keras.layers.concatenate([deep, wide]))\n",
    "\n",
    "  model = tf.keras.Model(input_layers, output)\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "      metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "  model.summary(print_fn=absl.logging.info)\n",
    "  return model\n",
    "\n",
    "# TFX Transform will call this function.\n",
    "def preprocessing_fn(inputs):\n",
    "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
    "\n",
    "  Args:\n",
    "    inputs: map from feature keys to raw not-yet-transformed features.\n",
    "\n",
    "  Returns:\n",
    "    Map from string feature key to transformed feature operations.\n",
    "  \"\"\"\n",
    "  outputs = {}\n",
    "  for key in _DENSE_FLOAT_FEATURE_KEYS:\n",
    "    # Preserve this feature as a dense float, setting nan's to the mean.\n",
    "    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n",
    "        _fill_in_missing(inputs[key]))\n",
    "\n",
    "  for key in _VOCAB_FEATURE_KEYS:\n",
    "    # Build a vocabulary for this feature.\n",
    "    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n",
    "        _fill_in_missing(inputs[key]),\n",
    "        top_k=_VOCAB_SIZE,\n",
    "        num_oov_buckets=_OOV_SIZE)\n",
    "\n",
    "  for key in _BUCKET_FEATURE_KEYS:\n",
    "    outputs[_transformed_name(key)] = tft.bucketize(\n",
    "        _fill_in_missing(inputs[key]),\n",
    "        _FEATURE_BUCKET_COUNT,\n",
    "        always_return_num_quantiles=False)\n",
    "\n",
    "  for key in _CATEGORICAL_FEATURE_KEYS:\n",
    "    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n",
    "\n",
    "  # Was this passenger a big tipper?\n",
    "  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n",
    "  tips = _fill_in_missing(inputs[_LABEL_KEY])\n",
    "  outputs[_transformed_name(_LABEL_KEY)] = tf.where(\n",
    "      tf.math.is_nan(taxi_fare),\n",
    "      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n",
    "      # Test if the tip was > 20% of the fare.\n",
    "      tf.cast(\n",
    "          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n",
    "\n",
    "  return outputs\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "# def trainer_fn(fn_args: TrainerFnArgs):\n",
    "def run_fn(fn_args: TrainerFnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "  # Number of nodes in the first layer of the DNN\n",
    "  first_dnn_layer_size = 100\n",
    "  num_dnn_layers = 4\n",
    "  dnn_decay_factor = 0.7\n",
    "\n",
    "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "\n",
    "  train_dataset = _input_fn(fn_args.train_files, tf_transform_output, 40)\n",
    "  eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, 40)\n",
    "\n",
    "  mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "  with mirrored_strategy.scope():\n",
    "    model = _build_keras_model(\n",
    "        # Construct layers sizes with exponetial decay\n",
    "        hidden_units=[\n",
    "            max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n",
    "            for i in range(num_dnn_layers)\n",
    "        ])\n",
    "\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  signatures = {\n",
    "      'serving_default':\n",
    "          _get_serve_tf_examples_fn(model,\n",
    "                                    tf_transform_output).get_concrete_function(\n",
    "                                        tf.TensorSpec(\n",
    "                                            shape=[None],\n",
    "                                            dtype=tf.string,\n",
    "                                            name='examples')),\n",
    "  }\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 파이프라인 코드 생성 \n",
    "\n",
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
      "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from typing import Text\n",
    "\n",
    "from kfp import onprem\n",
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import Evaluator\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import InfraValidator\n",
    "from tfx.components import Pusher\n",
    "from tfx.components import ResolverNode\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import Transform\n",
    "from tfx.components.base import executor_spec\n",
    "from tfx.components.trainer.executor import GenericExecutor\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
    "from tfx.orchestration import pipeline\n",
    "from tfx.orchestration.kubeflow import kubeflow_dag_runner\n",
    "from tfx.proto import infra_validator_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Model\n",
    "from tfx.types.standard_artifacts import ModelBlessing\n",
    "from tfx.utils.dsl_utils import external_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각종 변수 설정\n",
    "\n",
    "파이프라인 이름 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pipeline_name = 'kubeflow_chicago_taxi_pipeline_demo'\n",
    "_notebook_name = 'nb-demo-tfx'\n",
    "_namespace_name = 'ns-sunghj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"_persistent_volume_claim\" 은 notebook server 생성 시에 만든 pvc.   \n",
    "* 만일 이름을 까먹었다면, ' kubectl get pv -n ns-sunghj | grep nb-demo-tfx-vol-1 | awk ‘{print $1}’' 으로 확인하자.  \n",
    "\n",
    "\"_persistent_volume\" 의 이름을 확인하려면, \n",
    "* ' kubectl get pv | grep nbserver-tfx-chicago-taxi-example-vol-1 '  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_persistent_volume_claim = f'{_notebook_name}-vol-1'\n",
    "_persistent_volume = 'pvc-e89b7baf-e37e-462f-af24-e4c276b84d52'\n",
    "_persistent_volume_mount = '/mnt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfx pod이 바라보게 될 각종 경로들을 설정\n",
    "* 입력 데이터 저장장소 : /mnt/tfx/data\n",
    "* 출력(meta정보) 데이터 저장장소 : /mnt/pipelines/tfx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All input and output data are kept in the PV.\n",
    "_input_base = os.path.join(_persistent_volume_mount, 'tfx')\n",
    "_data_root = os.path.join(_input_base, 'data')\n",
    "_output_base = os.path.join(_persistent_volume_mount, 'pipelines')\n",
    "_tfx_root = os.path.join(_output_base, 'tfx')\n",
    "_pipeline_root = os.path.join(_tfx_root, _pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taxi_utils.py 파일을 공유할 pv에 옮겨서 나중에 tfx pod가 활용할 수 있게 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./data-vol-1/tfx’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./data-vol-1/tfx \n",
    "!mv ./taxi_utils.py ./data-vol-1/tfx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_module_file = os.path.join(_input_base, 'taxi_utils.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 완료된 모델이 저장될 위치 설정. 나중에 pusher가 이 위치에 학습이 완료된 모델을 가져다 놓는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_serving_model_dir = _output_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfx 파이프라인 생성 코드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n",
    "                     module_file: Text, serving_model_dir: Text,\n",
    "                     direct_num_workers: int) -> pipeline.Pipeline:\n",
    "  \"\"\"Implements the chicago taxi pipeline with TFX and Kubeflow Pipelines.\"\"\"\n",
    "  examples = external_input(data_root)\n",
    "\n",
    "  # Brings data into the pipeline or otherwise joins/converts training data.\n",
    "  example_gen = CsvExampleGen(input=examples)\n",
    "\n",
    "  # Computes statistics over data for visualization and example validation.\n",
    "  statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "\n",
    "  # Generates schema based on statistics files.\n",
    "  schema_gen = SchemaGen(\n",
    "      statistics=statistics_gen.outputs['statistics'],\n",
    "      infer_feature_shape=False)\n",
    "\n",
    "  # Performs anomaly detection based on statistics and data schema.\n",
    "  example_validator = ExampleValidator(\n",
    "      statistics=statistics_gen.outputs['statistics'],\n",
    "      schema=schema_gen.outputs['schema'])\n",
    "\n",
    "  # Performs transformations and feature engineering in training and serving.\n",
    "  transform = Transform(\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      schema=schema_gen.outputs['schema'],\n",
    "      module_file=module_file)\n",
    "\n",
    "  # Uses user-provided Python function that implements a model using TF-Learn\n",
    "  # to train a model on Google Cloud AI Platform.\n",
    "  trainer = Trainer(\n",
    "      module_file=module_file,\n",
    "      custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
    "      examples=transform.outputs['transformed_examples'],\n",
    "      transform_graph=transform.outputs['transform_graph'],\n",
    "      schema=schema_gen.outputs['schema'],\n",
    "      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
    "      eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n",
    "  \n",
    "\n",
    "  # Uses TFMA to compute a evaluation statistics over features of a model and\n",
    "  # perform quality validation of a candidate model (compared to a baseline).\n",
    "  eval_config = tfma.EvalConfig(\n",
    "    model_specs=[\n",
    "        # This assumes a serving model with signature 'serving_default'. If\n",
    "        # using estimator based EvalSavedModel, add signature_name: 'eval' and \n",
    "        # remove the label_key.\n",
    "        tfma.ModelSpec(label_key='tips')\n",
    "    ],\n",
    "    metrics_specs=[\n",
    "        tfma.MetricsSpec(\n",
    "            # The metrics added here are in addition to those saved with the\n",
    "            # model (assuming either a keras model or EvalSavedModel is used).\n",
    "            # Any metrics added into the saved model (for example using\n",
    "            # model.compile(..., metrics=[...]), etc) will be computed\n",
    "            # automatically.\n",
    "            metrics=[\n",
    "                tfma.MetricConfig(class_name='ExampleCount')\n",
    "            ],\n",
    "            # To add validation thresholds for metrics saved with the model,\n",
    "            # add them keyed by metric name to the thresholds map.\n",
    "            thresholds = {\n",
    "                'binary_accuracy': tfma.MetricThreshold(\n",
    "                    value_threshold=tfma.GenericValueThreshold(\n",
    "                        lower_bound={'value': 0.5}),\n",
    "                    change_threshold=tfma.GenericChangeThreshold(\n",
    "                       direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                       absolute={'value': -1e-10}))\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    "    slicing_specs=[\n",
    "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
    "        tfma.SlicingSpec(),\n",
    "        # Data can be sliced along a feature column. In this case, data is\n",
    "        # sliced along feature column trip_start_hour.\n",
    "        tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
    "    ])\n",
    "\n",
    "  # Get the latest blessed model for model validation.\n",
    "  model_resolver = ResolverNode(\n",
    "      instance_name='latest_blessed_model_resolver',\n",
    "      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
    "      model=Channel(type=Model),\n",
    "      model_blessing=Channel(type=ModelBlessing))\n",
    "\n",
    "  evaluator = Evaluator(\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      model=trainer.outputs['model'],\n",
    "      baseline_model=model_resolver.outputs['model'],\n",
    "      # Change threshold will be ignored if there is no baseline (first run).\n",
    "      eval_config=eval_config)\n",
    "\n",
    "  # Performs infra validation of a candidate model to prevent unservable model\n",
    "  # from being pushed. In order to use InfraValidator component, persistent\n",
    "  # volume and its claim that the pipeline is using should be a ReadWriteMany\n",
    "  # access mode.\n",
    "  infra_validator = InfraValidator(\n",
    "      model=trainer.outputs['model'],\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      serving_spec=infra_validator_pb2.ServingSpec(\n",
    "          tensorflow_serving=infra_validator_pb2.TensorFlowServing(\n",
    "              tags=['latest']),\n",
    "          kubernetes=infra_validator_pb2.KubernetesConfig()),\n",
    "      request_spec=infra_validator_pb2.RequestSpec(\n",
    "          tensorflow_serving=infra_validator_pb2.TensorFlowServingRequestSpec())\n",
    "  )\n",
    "\n",
    "  # Checks whether the model passed the validation steps and pushes the model\n",
    "  # to  Google Cloud AI Platform if check passed.\n",
    "  pusher = Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      model_blessing=evaluator.outputs['blessing'],\n",
    "      infra_blessing=infra_validator.outputs['blessing'],\n",
    "      push_destination=pusher_pb2.PushDestination(\n",
    "          filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  return pipeline.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      components=[\n",
    "          example_gen,\n",
    "          statistics_gen,\n",
    "          schema_gen,\n",
    "          example_validator,\n",
    "          transform,\n",
    "          trainer,\n",
    "          model_resolver,\n",
    "          evaluator,\n",
    "          infra_validator,\n",
    "          pusher,\n",
    "      ],\n",
    "      beam_pipeline_args=['--direct_num_workers=%d' % direct_num_workers],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfx에서 사용할 메타정보 저장소 설정. Kubeflow의 메타정보 저장소를 활용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grpc_config {\n",
      "  grpc_service_host {\n",
      "    value: \"metadata-grpc-service.kubeflow\"\n",
      "  }\n",
      "  grpc_service_port {\n",
      "    value: \"8080\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from tfx.orchestration.kubeflow.proto import kubeflow_pb2\n",
    "\n",
    "# metadata_config = kubeflow_pb2.KubeflowMetadataConfig()\n",
    "metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()\n",
    "metadata_config.grpc_config.grpc_service_host.value = 'metadata-grpc-service.kubeflow'\n",
    "metadata_config.grpc_config.grpc_service_port.value = '8080'\n",
    "# metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()\n",
    "print(metadata_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KubeflowDagRunner 를 사용하여 작성한 TFX 파이프라인을 Kubeflow 파이프라인으로 생성.   \n",
    "실행 후에는, chicago_taxi_pipeline_kubeflow_pvc.tar.gz 라는 Kubeflow 파이프라인 패키지가 생성됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  # This pipeline automatically injects the Kubeflow TFX image if the\n",
    "  # environment variable 'KUBEFLOW_TFX_IMAGE' is defined. Currently, the tfx\n",
    "  # cli tool exports the environment variable to pass to the pipelines.\n",
    "# tfx_image = os.environ.get('KUBEFLOW_TFX_IMAGE', None)\n",
    "    tfx_image = 'gcr.io/tfx-oss-public/tfx:0.22.0'\n",
    "\n",
    "    runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n",
    "      kubeflow_metadata_config=metadata_config,\n",
    "      # Specify custom docker image to use.\n",
    "      tfx_image=tfx_image,\n",
    "      pipeline_operator_funcs=(\n",
    "          [\n",
    "              onprem.mount_pvc(_persistent_volume_claim, _persistent_volume,\n",
    "                               _persistent_volume_mount)\n",
    "          ]))\n",
    "\n",
    "    kubeflow_dag_runner.KubeflowDagRunner(config=runner_config).run(\n",
    "      _create_pipeline(\n",
    "          pipeline_name=_pipeline_name,\n",
    "          pipeline_root=_pipeline_root,\n",
    "          data_root=_data_root,\n",
    "          module_file=_module_file,\n",
    "          serving_model_dir=_serving_model_dir,\n",
    "          # 0 means auto-detect based on the number of CPUs available during\n",
    "          # execution time.\n",
    "          direct_num_workers=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. pipeline 실행\n",
    "\n",
    "파이프라인 자동실행을 위한 rbac 설정.  \n",
    "파이프라인을 실행시키는 서비스의 api로 요청을 보내기 위해서는 현재 namespace의 role binding을 통해 권한을 설정해야 한다.  \n",
    "사용자 namespace 이름인 \"ns-sunghj\" 를 비롯한 설정값을 확인하고 입력하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rbac_file = f\"\"\"apiVersion: rbac.istio.io/v1alpha1\n",
    "kind: ServiceRoleBinding\n",
    "metadata:\n",
    "  name: bind-ml-pipeline-nb-{_namespace_name}\n",
    "  namespace: kubeflow\n",
    "spec:\n",
    "  roleRef:\n",
    "    kind: ServiceRole\n",
    "    name: ml-pipeline-services\n",
    "  subjects:\n",
    "    - properties:\n",
    "        source.principal: cluster.local/ns/{_namespace_name}/sa/default-editor\n",
    "\"\"\"\n",
    "with open('rbac.yaml', 'w') as writer:\n",
    "    writer.write(_rbac_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이프라인 자동실행을 위한 envoy filter 설정.   \n",
    "파이프라인을 실행시키는 서비스의 api로 요청을 보내기 위해서는 kubeflow-userid 정보를 http 헤더에 보내야 하는데, 현재 버전에서 누락된 문제가 있다. 이를 해결하기 위해 envoy filter에 http 헤더를 추가하도록 설정한다.  \n",
    "다음의 설정값들을 확인하고 입력하자.\n",
    "* namespace (ns-sunghj) : 사용자 namespace\n",
    "* header value (anonymous@kubeflow.org) : 다음의 명령으로 확인. \"kubectl describe profiles ns-sunghj\" (Owner값)\n",
    "* notebook-name (nbserver-tfx-chicago-taxi-example) : 다음의 명령으로 확인 \"kubectl get pod -n ns-sunghj --show-labels\" (label의 notebook-name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_envoyfilter_file = f\"\"\"apiVersion: networking.istio.io/v1alpha3\n",
    "kind: EnvoyFilter\n",
    "metadata:\n",
    "  name: add-header-nbserver-tfx-chicago-taxi-example\n",
    "  namespace: {_namespace_name}\n",
    "spec:\n",
    "  configPatches:\n",
    "    - applyTo: VIRTUAL_HOST\n",
    "      match:\n",
    "        context: SIDECAR_OUTBOUND\n",
    "        routeConfiguration:\n",
    "          vhost:\n",
    "            name: ml-pipeline.kubeflow.svc.cluster.local:8888\n",
    "            route:\n",
    "              name: default\n",
    "      patch:\n",
    "        operation: MERGE\n",
    "        value:\n",
    "          request_headers_to_add:\n",
    "            - append: true\n",
    "              header:\n",
    "                key: kubeflow-userid\n",
    "                value: anonymous@kubeflow.org\n",
    "  workloadSelector:\n",
    "    labels:\n",
    "      notebook-name: {_notebook_name}\n",
    "\"\"\"\n",
    "with open('envoyfilter.yaml', 'w') as writer:\n",
    "    writer.write(_envoyfilter_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"kubectl apply -f rbac.yaml\" 명령은 사용자 namespace 안에 있는 현 notebook에서는 권한이 없어 실행할 수 없다.   \n",
    "접근권한을 가진 shell에서 실행하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "envoyfilter.networking.istio.io/add-header-nbserver-tfx-chicago-taxi-example unchanged\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f envoyfilter.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이프라인 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/96e41b97-9504-42b6-b159-41ac861187c4\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/af5a30b6-7240-404c-b722-832b9b7038cb\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kfp\n",
    "run_result = kfp.Client(\n",
    "#     host=None  # replace with Kubeflow Pipelines endpoint if this notebook is run outside of the Kubeflow cluster.\n",
    "#      host=\"ml-pipeline.kubeflow.svc.cluster.local:8888\"\n",
    "    \n",
    "#     client_id=\"anonymous@kubeflow.org\"\n",
    ").create_run_from_pipeline_package('kubeflow_chicago_taxi_pipeline_demo.tar.gz', arguments={},namespace=\"ns-sunghj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
